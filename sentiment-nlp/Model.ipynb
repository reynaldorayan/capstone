{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b96792c9-08fe-455c-abe8-deb4ae9e1c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /home/nayar/.config/jupyterlab-desktop/envs/nlp_env/lib/python3.12/site-packages (1.5.1)\n",
      "Requirement already satisfied: deep-translator in /home/nayar/.config/jupyterlab-desktop/envs/nlp_env/lib/python3.12/site-packages (1.11.4)\n",
      "Requirement already satisfied: nltk in /home/nayar/.config/jupyterlab-desktop/envs/nlp_env/lib/python3.12/site-packages (3.8.1)\n",
      "Requirement already satisfied: fastapi in /home/nayar/.config/jupyterlab-desktop/envs/nlp_env/lib/python3.12/site-packages (0.111.0)\n",
      "Requirement already satisfied: matplotlib in /home/nayar/.config/jupyterlab-desktop/envs/nlp_env/lib/python3.12/site-packages (3.8.4)\n",
      "Requirement already satisfied: tensorflow[and-cuda] in /home/nayar/.config/jupyterlab-desktop/envs/nlp_env/lib/python3.12/site-packages (2.17.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/nayar/.config/jupyterlab-desktop/envs/nlp_env/lib/python3.12/site-packages (from tensorflow[and-cuda]) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/nayar/.config/jupyterlab-desktop/envs/nlp_env/lib/python3.12/site-packages (from tensorflow[and-cuda]) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /home/nayar/.config/jupyterlab-desktop/envs/nlp_env/lib/python3.12/site-packages (from tensorflow[and-cuda]) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /home/nayar/.config/jupyterlab-desktop/envs/nlp_env/lib/python3.12/site-packages (from tensorflow[and-cuda]) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/nayar/.config/jupyterlab-desktop/envs/nlp_env/lib/python3.12/site-packages (from tensorflow[and-cuda]) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /home/nayar/.config/jupyterlab-desktop/envs/nlp_env/lib/python3.12/site-packages (from tensorflow[and-cuda]) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/nayar/.config/jupyterlab-desktop/envs/nlp_env/lib/python3.12/site-packages (from tensorflow[and-cuda]) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /home/nayar/.config/jupyterlab-desktop/envs/nlp_env/lib/python3.12/site-packages (from tensorflow[and-cuda]) (0.4.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/nayar/.config/jupyterlab-desktop/envs/nlp_env/lib/python3.12/site-packages (from tensorflow[and-cuda]) (3.3.0)\n",
      "Requirement already satisfied: packaging in /home/nayar/.config/jupyterlab-desktop/envs/nlp_env/lib/python3.12/site-packages (from tensorflow[and-cuda]) (20.9)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /home/nayar/.config/jupyterlab-desktop/envs/nlp_env/lib/python3.12/site-packages (from tensorflow[and-cuda]) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/nayar/.config/jupyterlab-desktop/envs/nlp_env/lib/python3.12/site-packages (from tensorflow[and-cuda]) (2.32.2)\n",
      "Requirement already satisfied: setuptools in /home/nayar/.config/jupyterlab-desktop/envs/nlp_env/lib/python3.12/site-packages (from tensorflow[and-cuda]) (70.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/nayar/.config/jupyterlab-desktop/envs/nlp_env/lib/python3.12/site-packages (from tensorflow[and-cuda]) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/nayar/.config/jupyterlab-desktop/envs/nlp_env/lib/python3.12/site-packages (from tensorflow[and-cuda]) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/nayar/.config/jupyterlab-desktop/envs/nlp_env/lib/python3.12/site-packages (from tensorflow[and-cuda]) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/nayar/.config/jupyterlab-desktop/envs/nlp_env/lib/python3.12/site-packages (from tensorflow[and-cuda]) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/nayar/.config/jupyterlab-desktop/envs/nlp_env/lib/python3.12/site-packages (from tensorflow[and-cuda]) (1.64.1)\n",
      "Requirement already satisfied: tensorboard<2.18,>=2.17 in /home/nayar/.config/jupyterlab-desktop/envs/nlp_env/lib/python3.12/site-packages (from tensorflow[and-cuda]) (2.17.0)\n",
      "Requirement already satisfied: keras>=3.2.0 in /home/nayar/.config/jupyterlab-desktop/envs/nlp_env/lib/python3.12/site-packages (from tensorflow[and-cuda]) (3.4.1)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in /home/nayar/.config/jupyterlab-desktop/envs/nlp_env/lib/python3.12/site-packages (from tensorflow[and-cuda]) (1.26.4)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.3.4.1 in /home/nayar/.config/jupyterlab-desktop/envs/nlp_env/lib/python3.12/site-packages (from tensorflow[and-cuda]) (12.3.4.1)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.3.101 in /home/nayar/.config/jupyterlab-desktop/envs/nlp_env/lib/python3.12/site-packages (from tensorflow[and-cuda]) (12.3.101)\n",
      "Requirement already satisfied: nvidia-cuda-nvcc-cu12==12.3.107 in /home/nayar/.config/jupyterlab-desktop/envs/nlp_env/lib/python3.12/site-packages (from tensorflow[and-cuda]) (12.3.107)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.3.107 in /home/nayar/.config/jupyterlab-desktop/envs/nlp_env/lib/python3.12/site-packages (from tensorflow[and-cuda]) (12.3.107)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.3.101 in /home/nayar/.config/jupyterlab-desktop/envs/nlp_env/lib/python3.12/site-packages (from tensorflow[and-cuda]) (12.3.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.7.29 in /home/nayar/.config/jupyterlab-desktop/envs/nlp_env/lib/python3.12/site-packages (from tensorflow[and-cuda]) (8.9.7.29)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.12.1 in /home/nayar/.config/jupyterlab-desktop/envs/nlp_env/lib/python3.12/site-packages (from tensorflow[and-cuda]) (11.0.12.1)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.4.107 in /home/nayar/.config/jupyterlab-desktop/envs/nlp_env/lib/python3.12/site-packages (from tensorflow[and-cuda]) (10.3.4.107)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.5.4.101 in /home/nayar/.config/jupyterlab-desktop/envs/nlp_env/lib/python3.12/site-packages (from tensorflow[and-cuda]) (11.5.4.101)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.2.0.103 in /home/nayar/.config/jupyterlab-desktop/envs/nlp_env/lib/python3.12/site-packages (from tensorflow[and-cuda]) (12.2.0.103)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/nayar/.config/jupyterlab-desktop/envs/nlp_env/lib/python3.12/site-packages (from tensorflow[and-cuda]) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.3.101 in /home/nayar/.config/jupyterlab-desktop/envs/nlp_env/lib/python3.12/site-packages (from tensorflow[and-cuda]) (12.3.101)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/nayar/.config/jupyterlab-desktop/envs/nlp_env/lib/python3.12/site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/nayar/.config/jupyterlab-desktop/envs/nlp_env/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/nayar/.config/jupyterlab-desktop/envs/nlp_env/lib/python3.12/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.9.1 in /home/nayar/.config/jupyterlab-desktop/envs/nlp_env/lib/python3.12/site-packages (from deep-translator) (4.12.3)\n",
      "Requirement already satisfied: click in /home/nayar/.config/jupyterlab-desktop/envs/nlp_env/lib/python3.12/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/nayar/.config/jupyterlab-desktop/envs/nlp_env/lib/python3.12/site-packages (from nltk) (2024.5.15)\n",
      "Requirement already satisfied: tqdm in /home/nayar/.config/jupyterlab-desktop/envs/nlp_env/lib/python3.12/site-packages (from nltk) (4.66.4)\n",
      "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in /home/nayar/.config/jupyterlab-desktop/envs/nlp_env/lib/python3.12/site-packages (from fastapi) (0.37.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /home/nayar/.config/jupyterlab-desktop/envs/nlp_env/lib/python3.12/site-packages (from fastapi) (2.8.2)\n",
      "Requirement already satisfied: fastapi-cli>=0.0.2 in /home/nayar/.config/jupyterlab-desktop/envs/nlp_env/lib/python3.12/site-packages (from fastapi) (0.0.4)\n",
      "Requirement already satisfied: httpx>=0.23.0 in /home/nayar/.config/jupyterlab-desktop/envs/nlp_env/lib/python3.12/site-packages (from fastapi) (0.27.0)\n",
      "Requirement already satisfied: jinja2>=2.11.2 in /home/nayar/.config/jupyterlab-desktop/envs/nlp_env/lib/python3.12/site-packages (from fastapi) (3.1.4)\n",
      "Requirement already satisfied: python-multipart>=0.0.7 in /home/nayar/.config/jupyterlab-desktop/envs/nlp_env/lib/python3.12/site-packages (from fastapi) (0.0.9)\n",
      "Requirement already satisfied: ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 in /home/nayar/.config/jupyterlab-desktop/envs/nlp_env/lib/python3.12/site-packages (from fastapi) (5.10.0)\n",
      "Requirement already satisfied: orjson>=3.2.1 in /home/nayar/.config/jupyterlab-desktop/envs/nlp_env/lib/python3.12/site-packages (from fastapi) (3.10.6)\n",
      "Requirement already satisfied: email_validator>=2.0.0 in /home/nayar/.config/jupyterlab-desktop/envs/nlp_env/lib/python3.12/site-packages (from fastapi) (2.2.0)\n",
      "Requirement already satisfied: uvicorn>=0.12.0 in /home/nayar/.config/jupyterlab-desktop/envs/nlp_env/lib/python3.12/site-packages (from uvicorn[standard]>=0.12.0->fastapi) (0.30.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/nayar/.config/jupyterlab-desktop/envs/nlp_env/lib/python3.12/site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/nayar/.config/jupyterlab-desktop/envs/nlp_env/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/nayar/.config/jupyterlab-desktop/envs/nlp_env/lib/python3.12/site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/nayar/.config/jupyterlab-desktop/envs/nlp_env/lib/python3.12/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: pillow>=8 in /home/nayar/.config/jupyterlab-desktop/envs/nlp_env/lib/python3.12/site-packages (from matplotlib) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/nayar/.config/jupyterlab-desktop/envs/nlp_env/lib/python3.12/site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/nayar/.config/jupyterlab-desktop/envs/nlp_env/lib/python3.12/site-packages (from matplotlib) (2.9.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/nayar/.config/jupyterlab-desktop/envs/nlp_env/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow[and-cuda]) (0.43.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/nayar/.config/jupyterlab-desktop/envs/nlp_env/lib/python3.12/site-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep-translator) (2.5)\n",
      "Requirement already satisfied: dnspython>=2.0.0 in /home/nayar/.config/jupyterlab-desktop/envs/nlp_env/lib/python3.12/site-packages (from email_validator>=2.0.0->fastapi) (2.6.1)\n",
      "Requirement already satisfied: idna>=2.0.0 in /home/nayar/.config/jupyterlab-desktop/envs/nlp_env/lib/python3.12/site-packages (from email_validator>=2.0.0->fastapi) (3.7)\n",
      "Requirement already satisfied: typer>=0.12.3 in /home/nayar/.config/jupyterlab-desktop/envs/nlp_env/lib/python3.12/site-packages (from fastapi-cli>=0.0.2->fastapi) (0.12.3)\n",
      "Requirement already satisfied: anyio in /home/nayar/.config/jupyterlab-desktop/envs/nlp_env/lib/python3.12/site-packages (from httpx>=0.23.0->fastapi) (4.3.0)\n",
      "Requirement already satisfied: certifi in /home/nayar/.config/jupyterlab-desktop/envs/nlp_env/lib/python3.12/site-packages (from httpx>=0.23.0->fastapi) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /home/nayar/.config/jupyterlab-desktop/envs/nlp_env/lib/python3.12/site-packages (from httpx>=0.23.0->fastapi) (1.0.5)\n",
      "Requirement already satisfied: sniffio in /home/nayar/.config/jupyterlab-desktop/envs/nlp_env/lib/python3.12/site-packages (from httpx>=0.23.0->fastapi) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/nayar/.config/jupyterlab-desktop/envs/nlp_env/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.23.0->fastapi) (0.14.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/nayar/.config/jupyterlab-desktop/envs/nlp_env/lib/python3.12/site-packages (from jinja2>=2.11.2->fastapi) (2.1.5)\n",
      "Requirement already satisfied: rich in /home/nayar/.config/jupyterlab-desktop/envs/nlp_env/lib/python3.12/site-packages (from keras>=3.2.0->tensorflow[and-cuda]) (13.7.1)\n",
      "Requirement already satisfied: namex in /home/nayar/.config/jupyterlab-desktop/envs/nlp_env/lib/python3.12/site-packages (from keras>=3.2.0->tensorflow[and-cuda]) (0.0.8)\n",
      "Requirement already satisfied: optree in /home/nayar/.config/jupyterlab-desktop/envs/nlp_env/lib/python3.12/site-packages (from keras>=3.2.0->tensorflow[and-cuda]) (0.12.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/nayar/.config/jupyterlab-desktop/envs/nlp_env/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /home/nayar/.config/jupyterlab-desktop/envs/nlp_env/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/nayar/.config/jupyterlab-desktop/envs/nlp_env/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow[and-cuda]) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/nayar/.config/jupyterlab-desktop/envs/nlp_env/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow[and-cuda]) (2.2.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/nayar/.config/jupyterlab-desktop/envs/nlp_env/lib/python3.12/site-packages (from tensorboard<2.18,>=2.17->tensorflow[and-cuda]) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/nayar/.config/jupyterlab-desktop/envs/nlp_env/lib/python3.12/site-packages (from tensorboard<2.18,>=2.17->tensorflow[and-cuda]) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/nayar/.config/jupyterlab-desktop/envs/nlp_env/lib/python3.12/site-packages (from tensorboard<2.18,>=2.17->tensorflow[and-cuda]) (3.0.3)\n",
      "Requirement already satisfied: httptools>=0.5.0 in /home/nayar/.config/jupyterlab-desktop/envs/nlp_env/lib/python3.12/site-packages (from uvicorn[standard]>=0.12.0->fastapi) (0.6.1)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /home/nayar/.config/jupyterlab-desktop/envs/nlp_env/lib/python3.12/site-packages (from uvicorn[standard]>=0.12.0->fastapi) (1.0.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/nayar/.config/jupyterlab-desktop/envs/nlp_env/lib/python3.12/site-packages (from uvicorn[standard]>=0.12.0->fastapi) (6.0.1)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /home/nayar/.config/jupyterlab-desktop/envs/nlp_env/lib/python3.12/site-packages (from uvicorn[standard]>=0.12.0->fastapi) (0.19.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /home/nayar/.config/jupyterlab-desktop/envs/nlp_env/lib/python3.12/site-packages (from uvicorn[standard]>=0.12.0->fastapi) (0.22.0)\n",
      "Requirement already satisfied: websockets>=10.4 in /home/nayar/.config/jupyterlab-desktop/envs/nlp_env/lib/python3.12/site-packages (from uvicorn[standard]>=0.12.0->fastapi) (12.0)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /home/nayar/.config/jupyterlab-desktop/envs/nlp_env/lib/python3.12/site-packages (from typer>=0.12.3->fastapi-cli>=0.0.2->fastapi) (1.5.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/nayar/.config/jupyterlab-desktop/envs/nlp_env/lib/python3.12/site-packages (from rich->keras>=3.2.0->tensorflow[and-cuda]) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/nayar/.config/jupyterlab-desktop/envs/nlp_env/lib/python3.12/site-packages (from rich->keras>=3.2.0->tensorflow[and-cuda]) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/nayar/.config/jupyterlab-desktop/envs/nlp_env/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow[and-cuda]) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow[and-cuda] scikit-learn deep-translator nltk fastapi matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a368e77a-1799-4328-956e-9470d868e144",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-17 13:21:58.191838: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-17 13:21:58.443775: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-17 13:21:58.520994: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-17 13:21:58.696996: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-17 13:22:09.419323: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Input, Dense, Embedding, Bidirectional, Dropout, LSTM  # type: ignore\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer  # type: ignore\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences  # type: ignore\n",
    "from tensorflow.keras.models import Sequential  # type: ignore\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0d8ca08-5a16-46d5-ac31-9941d0b0ab6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated negative.csv: ./negative.csv\n"
     ]
    }
   ],
   "source": [
    "# Define the output path for the negative reviews CSV\n",
    "output_path_neg = \"./negative.csv\"\n",
    "\n",
    "# Define the path to the dataset\n",
    "ds_path = \"./Hotel_Reviews.csv\"\n",
    " \n",
    "# Remove the file if it already exists\n",
    "if os.path.exists(output_path_neg):\n",
    "    os.remove(output_path_neg)\n",
    "\n",
    "# Read the data from Hotel_Reviews.csv\n",
    "reviews_df = pd.read_csv(ds_path)\n",
    "\n",
    "# Clean up whitespace in \"Negative_Review\" column\n",
    "reviews_df[\"Negative_Review\"] = reviews_df[\"Negative_Review\"].apply(lambda x: re.sub(r'\\s+', ' ', x.strip()))\n",
    "\n",
    "# Define list of phrases to filter out\n",
    "phrases_to_filter = [\"no negative\", \"no negatives\", \"all ok\", \"nothing\", \"n a\", \"no problem\", \"no problems\", \"none\", \"i loved everything\", \"no bad experiences\", \"\"]\n",
    "\n",
    "# Filter out rows with specific phrases in \"Negative_Review\" (case insensitive)\n",
    "reviews_df = reviews_df[~reviews_df[\"Negative_Review\"].str.lower().isin(phrases_to_filter)]\n",
    "\n",
    "# Append the cleaned negative text reviews to a new \"review\" column\n",
    "reviews_df[\"review\"] = reviews_df[\"Negative_Review\"]\n",
    "\n",
    "# Create the \"sentiment\" column with value 0 (negative sentiment)\n",
    "reviews_df[\"sentiment\"] = 0\n",
    "\n",
    "# Select only the \"review\" and \"sentiment\" columns\n",
    "reviews_df = reviews_df[[\"review\", \"sentiment\"]]\n",
    "\n",
    "# Save the new DataFrame as a CSV\n",
    "reviews_df.to_csv(output_path_neg, index=False)\n",
    "\n",
    "# Print confirmation message\n",
    "print(f\"Generated negative.csv: {output_path_neg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c962ca4a-2960-4a9d-bdbe-49cb148f07b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated positive.csv: ./positive.csv\n"
     ]
    }
   ],
   "source": [
    "# Define the output path for the positive reviews CSV\n",
    "output_path_pos = \"./positive.csv\"\n",
    "\n",
    "# Define the path to the dataset\n",
    "ds_path = \"./Hotel_Reviews.csv\"\n",
    " \n",
    "# Remove the file if it already exists\n",
    "if os.path.exists(output_path_pos):\n",
    "    os.remove(output_path_pos)\n",
    "\n",
    "# Read the data from Hotel_Reviews.csv\n",
    "reviews_df = pd.read_csv(ds_path)\n",
    "\n",
    "# Clean up whitespace in \"Positive_Review\" column\n",
    "reviews_df[\"Positive_Review\"] = reviews_df[\"Positive_Review\"].apply(lambda x: re.sub(r'\\s+', ' ', x.strip()))\n",
    "\n",
    "# Define list of phrases to filter out (if needed for positive reviews)\n",
    "# For positive reviews, you might filter out phrases like \"no positive\", \"none\", etc.\n",
    "phrases_to_filter = [\"no positive\", \"no positives\", \"none\", \"\"]\n",
    "\n",
    "# Filter out rows with specific phrases in \"Positive_Review\" (case insensitive)\n",
    "reviews_df = reviews_df[~reviews_df[\"Positive_Review\"].str.lower().isin(phrases_to_filter)]\n",
    "\n",
    "# Append the cleaned positive text reviews to a new \"review\" column\n",
    "reviews_df[\"review\"] = reviews_df[\"Positive_Review\"]\n",
    "\n",
    "# Create the \"sentiment\" column with value 1 (positive sentiment)\n",
    "reviews_df[\"sentiment\"] = 1\n",
    "\n",
    "# Select only the \"review\" and \"sentiment\" columns\n",
    "reviews_df = reviews_df[[\"review\", \"sentiment\"]]\n",
    "\n",
    "# Save the new DataFrame as a CSV\n",
    "reviews_df.to_csv(output_path_pos, index=False)\n",
    "\n",
    "# Print confirmation message\n",
    "print(f\"Generated positive.csv: {output_path_pos}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3886bf66-a600-48a0-b0a0-db93097746ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined negative and positive file saved at: ./dataset.csv\n"
     ]
    }
   ],
   "source": [
    "# Define the paths for the input CSV files\n",
    "first_csv_path = \"./negative.csv\"\n",
    "second_csv_path = \"./positive.csv\"\n",
    "output_path = \"./dataset.csv\"\n",
    "\n",
    "# Read the data from the CSV files\n",
    "first_df = pd.read_csv(first_csv_path)\n",
    "second_df = pd.read_csv(second_csv_path)\n",
    "\n",
    "# Concatenate the DataFrames\n",
    "combined_df = pd.concat([first_df, second_df], ignore_index=True)\n",
    "\n",
    "# Delete the output file if it exists\n",
    "if os.path.exists(output_path):\n",
    "    os.remove(output_path)\n",
    "\n",
    "# Save the combined DataFrame as a new CSV\n",
    "combined_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Combined negative and positive file saved at: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ada5d5a1-08e0-4859-9eaf-379aa3ba62e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import os\n",
    "\n",
    "# # Define the path for the new CSV file\n",
    "# output_path = \"./second.csv\"\n",
    "\n",
    "# # Delete the file if it exists\n",
    "# if os.path.exists(output_path):\n",
    "#     os.remove(output_path)\n",
    "\n",
    "# # Read the data\n",
    "# reviews_df = pd.read_csv(\"./tripadvisor_hotel_reviews.csv\")\n",
    "\n",
    "# # Convert ratings to binary 1-0 scale for is_bad_review\n",
    "# def convert_rating(rating):\n",
    "#     if rating <= 2:\n",
    "#         return 0  # Bad review\n",
    "#     elif rating >= 4:\n",
    "#         return 1  # Good review\n",
    "#     else:\n",
    "#         return None  # Ignore neutral reviews with a rating of 3\n",
    "\n",
    "# reviews_df[\"sentiment\"] = reviews_df[\"Rating\"].apply(convert_rating)\n",
    "\n",
    "# # Drop neutral reviews\n",
    "# reviews_df = reviews_df.dropna(subset=[\"sentiment\"])\n",
    "\n",
    "# # Select only relevant columns\n",
    "# reviews_df = reviews_df[[\"Review\", \"sentiment\"]]\n",
    "# reviews_df.columns = [\"review\", \"sentiment\"]\n",
    "\n",
    "# # Convert sentiment to integer type\n",
    "# reviews_df[\"sentiment\"] = reviews_df[\"sentiment\"].astype(int)\n",
    "\n",
    "# # Save the new DataFrame as a CSV\n",
    "# reviews_df.to_csv(output_path, index=False)\n",
    "\n",
    "# print(f\"New CSV file saved at: {output_path}\")\n",
    "\n",
    "# # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d660b22-b939-4ad5-910a-68d2896149d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import os\n",
    "\n",
    "# # Define the paths for the input CSV files\n",
    "# first_csv_path = \"./first.csv\"\n",
    "# second_csv_path = \"./second.csv\"\n",
    "# output_path = \"./dataset.csv\"\n",
    "\n",
    "# # Read the data from the CSV files\n",
    "# first_df = pd.read_csv(first_csv_path)\n",
    "# second_df = pd.read_csv(second_csv_path)\n",
    "\n",
    "# # Concatenate the DataFrames\n",
    "# combined_df = pd.concat([first_df, second_df], ignore_index=True)\n",
    "\n",
    "# # Delete the output file if it exists\n",
    "# if os.path.exists(output_path):\n",
    "#     os.remove(output_path)\n",
    "\n",
    "# # Save the combined DataFrame as a new CSV\n",
    "# combined_df.to_csv(output_path, index=False)\n",
    "\n",
    "# print(f\"Combined CSV file saved at: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8ef1e97-a41a-4c1a-a929-f49c55fbede4",
   "metadata": {},
   "outputs": [],
   "source": [
    "TAG_RE = re.compile(r\"<[^>]+>\")\n",
    "STOPWORDS = set(stopwords.words(\"english\"))\n",
    "PUNCTUATIONS = re.compile(\"[^a-zA-Z]\")\n",
    "\n",
    "\n",
    "def preprocess_text(sen):\n",
    "    # Lowercase the text\n",
    "    sentence = sen.lower()\n",
    "    # Remove HTML tags\n",
    "    sentence = TAG_RE.sub(\"\", sentence)\n",
    "    # Remove punctuations\n",
    "    sentence = PUNCTUATIONS.sub(\" \", sentence)\n",
    "    # Remove single characters\n",
    "    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", \" \", sentence)\n",
    "    # Remove multiple spaces\n",
    "    sentence = re.sub(r\"\\s+\", \" \", sentence)\n",
    "    # Remove stopwords\n",
    "    sentence = \" \".join(word for word in sentence.split() if word not in STOPWORDS)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e323dbe-17f0-4e57-9eaa-909efe32500b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I am so angry that i made this post available ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rooms are nice but for elderly a bit difficult...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>My room was dirty and I was afraid to walk bar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You When I booked with your company on line yo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Backyard of the hotel is total mess shouldn t ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292579</th>\n",
       "      <td>Good location Nice big room</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292580</th>\n",
       "      <td>I loved the style of the hotel and the locatio...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292581</th>\n",
       "      <td>With a Subway station a few steps away it s ve...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292582</th>\n",
       "      <td>Room was clean nice as advertised</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292583</th>\n",
       "      <td>Friendly efficient staff We enjoyed breakfast ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>292584 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   review  sentiment\n",
       "0       I am so angry that i made this post available ...          0\n",
       "1       Rooms are nice but for elderly a bit difficult...          0\n",
       "2       My room was dirty and I was afraid to walk bar...          0\n",
       "3       You When I booked with your company on line yo...          0\n",
       "4       Backyard of the hotel is total mess shouldn t ...          0\n",
       "...                                                   ...        ...\n",
       "292579                        Good location Nice big room          1\n",
       "292580  I loved the style of the hotel and the locatio...          1\n",
       "292581  With a Subway station a few steps away it s ve...          1\n",
       "292582                  Room was clean nice as advertised          1\n",
       "292583  Friendly efficient staff We enjoyed breakfast ...          1\n",
       "\n",
       "[292584 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the CSV file\n",
    "reviews = pd.read_csv(\"./dataset.csv\")\n",
    "reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3e3e671-edcc-4692-989e-030f19c09aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(sen):\n",
    "    \n",
    "    # Lowercase the text\n",
    "    sentence = sen.lower()\n",
    "    # Remove HTML tags\n",
    "    sentence = TAG_RE.sub(\"\", sentence)\n",
    "    # Remove punctuations\n",
    "    sentence = PUNCTUATIONS.sub(\" \", sentence)\n",
    "    # Remove single characters\n",
    "    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", \" \", sentence)\n",
    "    # Remove multiple spaces\n",
    "    sentence = re.sub(r\"\\s+\", \" \", sentence)\n",
    "    # Remove stopwords\n",
    "    sentence = \" \".join(word for word in sentence.split() if word not in STOPWORDS)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "030dcf68-3966-4dd7-b02f-aa60f663c8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file\n",
    "reviews = pd.read_csv(\"./dataset.csv\")\n",
    "\n",
    "# Preprocess each review and store in a list of dictionaries\n",
    "data = []\n",
    "for i, row in reviews.iterrows():\n",
    "    # Check if the text is NaN\n",
    "    if isinstance(row[\"review\"], str):\n",
    "        review = preprocess_text(row[\"review\"])\n",
    "        data.append({\"org\": row[\"review\"], \"review\": review, \"sentiment\": row[\"sentiment\"]})\n",
    "        \n",
    "# Create DataFrame from the preprocessed data\n",
    "X = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ed2396c-2f8e-4adf-8b72-ce61a0783c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1721194123.266826   21751 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1721194123.723969   21751 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1721194123.726610   21751 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1721194123.741844   21751 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1721194123.744675   21751 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1721194123.747628   21751 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1721194124.343305   21751 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1721194124.346408   21751 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1721194124.349086   21751 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-17 13:28:44.350737: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2285 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2050, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: 234021\n",
      "Validation data shape: 58506\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training (80%) and validation (20%)\n",
    "train_data, val_data = train_test_split(X, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a TensorFlow dataset from the training data\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (train_data[\"review\"].values, train_data[\"sentiment\"].values)\n",
    ")\n",
    "\n",
    "# Shuffle and batch the training dataset\n",
    "batch_size = 32\n",
    "train_dataset = train_dataset.shuffle(buffer_size=len(train_data)).batch(batch_size)\n",
    "\n",
    "# Repeat the process for the validation dataset\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (val_data[\"review\"].values, val_data[\"sentiment\"].values)\n",
    ")\n",
    "val_dataset = val_dataset.batch(batch_size)\n",
    "\n",
    "# Print the shapes of the datasets\n",
    "print(\"Train data shape:\", len(train_data))\n",
    "print(\"Validation data shape:\", len(val_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8594396-3e7d-4192-82a6-ed61b86e7796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text data\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(train_data[\"review\"].values)\n",
    "\n",
    "with open(\"tokenizer.pickle\", \"wb\") as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# Convert text data to sequences\n",
    "X_train = tokenizer.texts_to_sequences(train_data[\"review\"].values)\n",
    "X_val = tokenizer.texts_to_sequences(val_data[\"review\"].values)\n",
    "\n",
    "# Pad sequences to ensure uniform length\n",
    "max_len = 100\n",
    "X_train = pad_sequences(X_train, maxlen=max_len, padding=\"post\")\n",
    "X_val = pad_sequences(X_val, maxlen=max_len, padding=\"post\")\n",
    "vocab_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20c06010-08f4-4c36-8729-19d76805e85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "\n",
    "    # Define the model\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(max_len,)))\n",
    "    model.add(Embedding(input_dim=vocab_size, output_dim=100))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Bidirectional(LSTM(100, dropout=0.2, recurrent_dropout=0.2)))\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=Adam(learning_rate=0.001), metrics=[\"accuracy\"])\n",
    "\n",
    "    # Train the model\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train,\n",
    "        train_data[\"sentiment\"].values,\n",
    "        epochs=10,\n",
    "        batch_size=32,\n",
    "        validation_data=(X_val, val_data[\"sentiment\"].values),\n",
    "        verbose=1,\n",
    "    )\n",
    "\n",
    "    # Plot training history\n",
    "\n",
    "    plt.plot(history.history[\"accuracy\"], label=\"accuracy\")\n",
    "    plt.plot(history.history[\"val_accuracy\"], label=\"val_accuracy\")\n",
    "\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20761e6d-002f-4295-b3cf-4b9a82fc030d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,684,600</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">160,800</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">201</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │     \u001b[38;5;34m3,684,600\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)            │       \u001b[38;5;34m160,800\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m201\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,845,603</span> (14.67 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,845,603\u001b[0m (14.67 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,845,601</span> (14.67 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,845,601\u001b[0m (14.67 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (12.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2\u001b[0m (12.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Path to your model file\n",
    "model_path = \"./sentiment.h5\"\n",
    "\n",
    "try:\n",
    "    # Attempt to load the model\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "    print(\"Loaded model from disk\")\n",
    "except (OSError, IOError) as e:\n",
    "    # If loading fails, create a new model and save it\n",
    "    print(f\"Model file {model_path} not found. Creating a new model.\")\n",
    "    model = create_model()\n",
    "    model.save(model_path)\n",
    "    print(f\"New model saved to {model_path}\")\n",
    "\n",
    "# Print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0b3ead-7016-4411-8a47-19dd4dc72d4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 489/1829\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11:54\u001b[0m 533ms/step - accuracy: 0.9373 - loss: 0.2041"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on test data\n",
    "loss, accuracy = model.evaluate(X_val, val_data[\"sentiment\"].values)\n",
    "\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8f93f7-a664-40a6-a6fe-e94b0f5d7053",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(review):\n",
    "    # Tokenize and pad the input review\n",
    "    review_seq = tokenizer.texts_to_sequences([preprocess_text(review)])\n",
    "    review_seq = pad_sequences(review_seq, maxlen=max_len, padding=\"post\")\n",
    "\n",
    "    # Make prediction\n",
    "    prediction = round(model.predict(review_seq)[0][0], 2)\n",
    "\n",
    "    # Return the prediction\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d74a1e-c3dd-4958-9c40-db0a7f8b935a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deep_translator import GoogleTranslator\n",
    "\n",
    "review = \"I love the resort\"\n",
    "\n",
    " # Translate the input review to English\n",
    "translatedText = GoogleTranslator(source=\"auto\", target=\"en\").translate(review)\n",
    "\n",
    "result = predict_sentiment(translatedText)\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
